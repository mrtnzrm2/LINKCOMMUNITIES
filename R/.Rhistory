xmodel <- get.optimized.xgboost(datasets, inst, filename = "2", on=F)
xgboost.model <- xmodel$model %>% tune::finalize_model(xmodel$parameters)
# Plots ----
make.importance(datasets, xgboost.model, inst, subfolder = subfolder, filename="2", on=F)
make.datasets(xgboost.model, datasets, inst, subfolder=subfolder, filename="2", on=T)
make.tree.depth(xmodel$tude, inst, subfolder=subfolder, filename="2", on=F)
}
### HEAD ###
folder <- 'merged'
distances <- 'original'
model <- 'normal'
csv.name <- 'fln'
labels.name <- 'rlabels'  # imputation_labels  rlabels
common.path <- paste(distances, model, sep = '/')
csv.path <- paste(folder, 'imputation', common.path, paste0(csv.name,'.csv'), sep = '/') # merged/imputation/tracto2016/zz_model/   91x40
labels.path <- paste(folder, 'labels', common.path, paste0(labels.name,'.csv'), sep = '/')
plot.path <- '../plots'
path.list <- list(csv=csv.path,
labels=labels.path,
plot=plot.path,
common=common.path,
folder=folder,
model=model,
distances=distances)
main(path.list)
setwd("/Users/jmarti53/Documents/ND/LINKCOMMUNITIES/MAC/220126/R")
split.dataset <- function(N, kfold=5){
nodes <- 1:N
ntrn <- N*((kfold-1)/kfold)
ntrn <- ntrn %>% as.integer()
ntst <- N - ntrn
training.nodes <- sample(nodes, ntrn, replace = F) %>% sort()
test.nodes <- nodes[!nodes %in% training.nodes] %>% sort()
split <- list(train=training.nodes, test=test.nodes, ntrn=ntrn, ntst=ntst)
return(split)
}
assemble.dataset.train <- function(net, train, test, labels, N){
train.labs <- labels[train]
test.labs <- labels[test]
ec.labs <- c(train.labs, test.labs)
noec.labs <- c(ec.labs, labels[(N+1):length(labels)])
net %>% as.data.frame()
colnames(net) <- labels[1:N]
rownames(net) <- labels
net <- net[noec.labs, ec.labs]
net <- net[noec.labs, train.labs] %>% as.matrix()
return(net)
}
assemble.dataset.test <- function(net, train, test, labels, N){
train.labs <- labels[train]
test.labs <- labels[test]
ec.labs <- c(train.labs, test.labs)
noec.labs <- c(ec.labs, labels[(N+1):length(labels)])
net %>% as.data.frame()
colnames(net) <- labels[1:N]
rownames(net) <- labels
net <- net[noec.labs, ec.labs]
net <- net[noec.labs, test.labs] %>% as.matrix()
return(net)
}
compute.aik <- function(net, N, mode="ALPHA"){
source("functions/aki.R")
source("functions/aik.R")
source("functions/jaccard_p_fast.R")
aik.matrix <- aik(net, mode=mode)
AIK <- matrix(0, nrow = N, ncol = N)
for (i in 1:N){
for (j in 1:N){
if (i < j){
AIK[i,j] <- jaccard.p.fast(aik.matrix[i,], aik.matrix[j,])
}
}
}
AIK <- AIK + t(AIK)
return(AIK)
}
compute.aki <- function(net, N, mode="ALPHA"){
source("functions/aki.R")
source("functions/aik.R")
source("functions/jaccard_p_fast.R")
aki.matrix <- aki(net, mode=mode)
AKI <- matrix(0, nrow = N, ncol = N)
for (i in 1:N){
for (j in 1:N){
if (i < j){
AKI[i,j] <- jaccard.p.fast(aki.matrix[i,], aki.matrix[j,])
}
}
}
AKI <- AKI + t(AKI)
return(AKI)
}
get.mean.similarity <- function(df, ntrn, ntgt, nsrc=107){
net <- df$net
AIK <- df$aik
AKI <- df$aki
AIK[diag(nsrc) == 1] <- NA
AKI[diag(ntrn) == 1] <- NA
similarity <- matrix(0, nrow = nsrc, ncol = ntgt)
for (i in 1:ntrn){
for (j in 1:ntrn){
if (i != j){
jacp.aik <- AIK[i,j]
jacp.aki <- AKI[i,j]
similarity[i,j] <- mean(c(jacp.aki, jacp.aik))
}
}
}
for (i in (ntrn+1):nsrc){
for (j in 1:ntrn){
Ni <- which(net[i,] > 0)
Nj <- which(net[j,] > 0)
NiNj <- Ni[Ni %in% Nj]
jacp.aik <- AIK[i,j]
jacp.aki <- mean(AKI[j, NiNj], na.rm = T)
similarity[i,j] <- mean(c(jacp.aki, jacp.aik))
}
}
for (i in 1:ntrn){
for (j in (ntrn+1):ntgt){
Ni <- which(net[i,] > 0)
Nj <- which(net[j,] > 0)
NiNj <- Ni[Ni %in% Nj]
jacp.aik <- AIK[i,j]
jacp.aki <- mean(AKI[i, NiNj], na.rm = T)
similarity[i,j] <- mean(c(jacp.aki, jacp.aik))
}
}
for (i in (ntrn+1):nsrc){
for (j in (ntrn+1):ntgt){
Ni <- which(net[i,] > 0)
Nj <- which(net[j,] > 0)
NiNj <- Ni[Ni %in% Nj]
jacp.aik <- AIK[i,j]
jacp.aki <- mean(AKI[NiNj, NiNj], na.rm = T)
similarity[i,j] <- mean(c(jacp.aki, jacp.aik))
}
}
return(similarity)
}
get.dataset <- function(net, nt, nodes, labels, inst, filename="1",save=T){
if (save){
source("functions/df_to_adj.R")
net <- net %>% df.to.adj()
net <- net[,1:nt]
source("functions/get_tracto2016.R")
distances <- get.tracto2016(labels)
distances <- distances[,1:nt]
source("functions/get_supra.R")
supra <- get.supra(labels)
supra[supra != 0] <- log10(supra[supra != 0])
source("functions/get_infra.R")
infra <- get.infra(labels)
infra[infra != 0] <- log10(infra[infra != 0])
# Separate training and test set ----
split <- split.dataset(nt)
## Assembling train data ----
source("functions/adj_to_df.R")
net.train <- assemble.dataset.train(net, split$train, split$test, labels, nt)
dist.train <- assemble.dataset.train(distances, split$train, split$test, labels, nt) %>% adj.to.df()
supra.train <-  assemble.dataset.train(supra, split$train, split$test, labels, nt)
infra.train <-  assemble.dataset.train(infra, split$train, split$test, labels, nt)
### Computing AKS ----
net.aik <- compute.aik(net.train %>% adj.to.df(), nodes)
net.aki <- compute.aki(net.train %>% adj.to.df(), split$ntrn)
supra.aik <- compute.aik(supra.train %>% adj.to.df(), nodes)
supra.aki <- compute.aki(supra.train %>% adj.to.df(), split$ntrn)
infra.aik <- compute.aik(infra.train %>% adj.to.df(), nodes)
infra.aki <- compute.aki(infra.train %>% adj.to.df(), split$ntrn)
### Get similarities ----
net.sim <- get.mean.similarity(list(net=net.train, aik=net.aik, aki=net.aki), split$ntrn, nodes)
supra.sim <- get.mean.similarity(list(net=supra.train, aik=supra.aik, aki=supra.aki), split$ntrn, nodes)
infra.sim <- get.mean.similarity(list(net=infra.train, aik=infra.aik, aki=infra.aki), split$ntrn, nodes)
### Get similarity train ----
net.sim.train <- net.sim[,1:split$ntrn] %>% adj.to.df()
supra.sim.train <- supra.sim[,1:split$ntrn] %>% adj.to.df()
infra.sim.train <- infra.sim[,1:split$ntrn] %>% adj.to.df()
## Assembling test data ----
net.test <- assemble.dataset.test(net, split$train, split$test, labels, nt) %>% adj.to.df()
dist.test <-  assemble.dataset.test(distances, split$train, split$test, labels, nt)  %>% adj.to.df()
### Get similarity test ----
net.sim.test <- net.sim[,(split$ntrn+1):nt] %>% adj.to.df()
supra.sim.test <- supra.sim[,(split$ntrn+1):nt] %>% adj.to.df()
infra.sim.test <- infra.sim[,(split$ntrn+1):nt] %>% adj.to.df()
## Form train data ----
net.train <- net.train %>% adj.to.df()
nozeros.train <- !net.train$weight == 0
train.data <- data.frame(w=net.train$weight[nozeros.train], supra=supra.sim.train$weight[nozeros.train], infra=infra.sim.train$weight[nozeros.train], dist=dist.train$weight[nozeros.train])
## Form test data ----
nozeros.test <- !net.test$weight == 0
test.data <- data.frame(w=net.test$weight[nozeros.test], supra=supra.sim.test$weight[nozeros.test], infra=infra.sim.test$weight[nozeros.test], dist=dist.test$weight[nozeros.test])
## Save train and test data ----
df <- list(train=train.data, test=test.data, split=split)
saveRDS(df, "../RDS/imputation/%s/dataset/%s.rds" %>% sprintf(inst$common, filename))
} else
df <- readRDS("../RDS/imputation/%s/dataset/%s.rds" %>% sprintf(inst$common, filename))
df <- structure(
list(
data = df$train %>% rbind(df$test) %>% dplyr::as_tibble(),
in_id = 1:nrow(df$train),
out_id = (nrow(df$train)+1):(nrow(df$train)+nrow(df$test))
),
class = "rsplit"
)
return(df)
}
get.optimized.xgboost <- function(datasets, inst, grid.size=60, filename="1", on=T){
if (on){
# Preprocessing ----
preprocessing.recipe <- recipes::recipe(w ~ ., rsample::training(datasets)) %>% recipes::prep()
train.cv.folds <- recipes::bake(preprocessing.recipe, new_data = rsample::training(datasets)) %>% rsample::vfold_cv(v = 5)
# XGBoost model specification ----
xgboost.model <- parsnip::boost_tree(
mode = "regression",
trees = 1000,
min_n = e1071::tune(),
tree_depth = e1071::tune(),
learn_rate = e1071::tune(),
loss_reduction = e1071::tune()
) %>%
parsnip::set_engine("xgboost", objective = "reg:squarederror")
# Grid specification ----
xgboost.params <-
dials::parameters(
dials::min_n(),
dials::tree_depth(),
dials::learn_rate(),
dials::loss_reduction()
)
xgboost.grid <-
dials::grid_max_entropy(
xgboost.params,
size = grid.size
)
# Define the workflow ----
xgboost.wf <-
workflows::workflow() %>%
workflows::add_model(xgboost.model) %>%
workflows::add_formula(w ~ .)
# Hyperparameter tuning ----
source("functions/num-rmae.R")
xgboost.tuned <- tune::tune_grid(
object = xgboost.wf,
resamples = train.cv.folds,
grid = xgboost.grid,
metrics = yardstick::metric_set(yardstick::rmse, yardstick::rsq, yardstick::mae, rmae),
control = tune::control_grid(verbose = TRUE)
)
# Review hyperparameters ----
p <- xgboost.tuned %>%
tune::show_best(metric = "rmae") %>%
knitr::kable()
print(p)
# Select best parameters ----
xgboost.best.params <- xgboost.tuned %>%
tune::select_best("rmae")
# Save object ----
l <- list(model=xgboost.model, parameters=xgboost.best.params, workflow=xgboost.wf, tune=xgboost.tuned)
saveRDS(l, "../RDS/imputation/%s/XGBOOST/%s.rds" %>% sprintf(inst$common, filename))
} else
l <- readRDS("../RDS/imputation/%s/XGBOOST/%s.rds" %>% sprintf(inst$common, filename))
return(l)
}
make.datasets <- function(model, datasets, inst, subfolder="", filename="", on=T){
if (on){
# Check in train ----
source("functions/rmae.R")
preprocessing.recipe <- recipes::recipe(w ~ ., rsample::training(datasets)) %>% recipes::prep()
train.processed <- recipes::bake(preprocessing.recipe,  new_data = rsample::training(datasets))
train.prediction <- model %>%
# fit the model on all the training data
parsnip::fit(
formula = w ~ .,
data    = train.processed
)  %>%
predict(new_data = train.processed) %>%
dplyr::bind_cols(rsample::training(datasets))
train.score <- dplyr::tibble(rmae=rmae(train.prediction$w, train.prediction$.pred)) %>%
knitr::kable()
print(train.score)
# Check in test ----
test.processed <- recipes::bake(preprocessing.recipe,  new_data = rsample::testing(datasets))
test.prediction <- model %>%
parsnip::fit(
formula = w ~ .,
data    = test.processed
)
# Explainer ----
explainer <- DALEX::explain(
model=test.prediction,
data=rsample::testing(datasets),
y= rsample::testing(datasets)$w,
label="XGboost"
)
modelStudio::modelStudio(explainer)
test.prediction <- test.prediction %>%
predict(new_data = test.processed) %>%
dplyr::bind_cols(rsample::testing(datasets))
test.score <- dplyr::tibble(rmae=rmae(test.prediction$w, test.prediction$.pred)) %>%
knitr::kable()
print(test.score)
# test.residuals <- test.prediction %>%
#   dplyr::arrange(.pred) %>%
#   dplyr::mutate(residual_pct = (w - .pred) / .pred) %>%
#   dplyr::select(.pred, residual_pct)
# p <- ggplot2::ggplot(test.residuals, ggplot2::aes(x = .pred, y = residual_pct)) +
#   ggplot2::geom_point(size=0.5)+
#   ggplot2::xlab("Predicted w")+
#   ggplot2::ylab("Residual (%)")+
#   ggplot2::geom_smooth()+
#   ggplot2::theme_classic()
#
# png("%s/%s/Regression/%s/residuals_test_%s.png" %>% sprintf(inst$plot, inst$folder, subfolder, filename), width = 6, height = 6, res = 200, units = "in")
# print(p)
# dev.off()
}
}
make.importance <- function(datasets, model, inst, subfolder="", filename="", on=T){
if (on){
print("* Plot importance of the variables")
# Plot importance ----
preprocessing.recipe <- recipes::recipe(w ~ ., rsample::training(datasets))
final.xgboost <- tune::last_fit(model, preprocessing.recipe, datasets)
p <- final.xgboost %>% tune::extract_fit_parsnip() %>% vip::vip()
png("%s/%s/Regression/%s/vip_%s.png" %>% sprintf(inst$plot, inst$folder, subfolder, filename), width = 6, height = 6, res = 200, units = "in")
print(p)
dev.off()
} else
print("* No importance")
}
make.tree.depth <- function(tuned, inst, subfolder="", filename="", on=T){
if (on){
print("* Plotting tree_depth")
p <- tuned %>%
tune::collect_metrics() %>%
dplyr::mutate(tree_depth = factor(tree_depth)) %>%
ggplot2::ggplot(ggplot2::aes(min_n, mean, color = tree_depth)) +
ggplot2::geom_line(size = 0.5, alpha = 0.6) +
ggplot2::geom_point(size = 1) +
ggplot2::facet_wrap(~ .metric, scales = "free", nrow = 3)
png("%s/%s/Regression/%s/tree_depth_%s.png" %>% sprintf(inst$plot, inst$folder, subfolder, filename), width = 6, height = 6, res = 200, units = "in")
print(p)
dev.off()
} else
print("* No tree_depth")
}
main <- function(inst){
library(magrittr)
set.seed(NULL)
nlog10 <- T
nt <- 50   ## Number of  columns
nodes <- 107
# Load network ----
source('functions/load_net.R')
netx <- load.net(inst)
net <- netx$net
leaves <- netx$leaves
labels <- netx$labels
source("functions/format_labels.R")
labels <- labels %>% format.labels()
subfolder <- "XGBOOST"
# Create folder ----
source('functions/sformat.R')
inst$mainfolder <- paste(inst$folder, "Regression", sep = "/")
dir.create(sprintf('%s/%s', inst$plot, inst$mainfolder), showWarnings = F)
dir.create(sprintf('%s/%s/%s', inst$plot, inst$mainfolder, subfolder), showWarnings = F)
if (nlog10){
net$weight[net$weight != 0] <- -log10(net$weight[net$weight != 0])
}
# Get datasets ----
datasets <- get.dataset(net, nt, nodes, labels, inst, filename="2",save=F)
# Parallelization ----
all_cores <- parallel::detectCores(logical = FALSE)
doParallel::registerDoParallel(cores = all_cores)
# Grid for hyperparameter optimization and Model ----
xmodel <- get.optimized.xgboost(datasets, inst, filename = "2", on=F)
xgboost.model <- xmodel$model %>% tune::finalize_model(xmodel$parameters)
# Plots ----
make.importance(datasets, xgboost.model, inst, subfolder = subfolder, filename="2", on=F)
make.datasets(xgboost.model, datasets, inst, subfolder=subfolder, filename="2", on=T)
make.tree.depth(xmodel$tude, inst, subfolder=subfolder, filename="2", on=F)
}
### HEAD ###
folder <- 'merged'
distances <- 'original'
model <- 'normal'
csv.name <- 'fln'
labels.name <- 'rlabels'  # imputation_labels  rlabels
common.path <- paste(distances, model, sep = '/')
csv.path <- paste(folder, 'imputation', common.path, paste0(csv.name,'.csv'), sep = '/') # merged/imputation/tracto2016/zz_model/   91x40
labels.path <- paste(folder, 'labels', common.path, paste0(labels.name,'.csv'), sep = '/')
plot.path <- '../plots'
path.list <- list(csv=csv.path,
labels=labels.path,
plot=plot.path,
common=common.path,
folder=folder,
model=model,
distances=distances)
main(path.list)
make.datasets <- function(model, datasets, inst, subfolder="", filename="", on=T){
if (on){
# Check in train ----
source("functions/rmae.R")
preprocessing.recipe <- recipes::recipe(w ~ ., rsample::training(datasets)) %>% recipes::prep()
train.processed <- recipes::bake(preprocessing.recipe,  new_data = rsample::training(datasets))
train.prediction <- model %>%
# fit the model on all the training data
parsnip::fit(
formula = w ~ .,
data    = train.processed
)  %>%
predict(new_data = train.processed) %>%
dplyr::bind_cols(rsample::training(datasets))
train.score <- dplyr::tibble(rmae=rmae(train.prediction$w, train.prediction$.pred)) %>%
knitr::kable()
print(train.score)
# Check in test ----
test.processed <- recipes::bake(preprocessing.recipe,  new_data = rsample::testing(datasets))
test.prediction <- model %>%
parsnip::fit(
formula = w ~ .,
data    = test.processed
)
# Explainer ----
explainer <- DALEX::explain(
model=test.prediction,
data=rsample::testing(datasets),
y= rsample::testing(datasets)$w,
label="XGboost"
)
modelStudio::modelStudio(explainer, viewer="internal")
test.prediction <- test.prediction %>%
predict(new_data = test.processed) %>%
dplyr::bind_cols(rsample::testing(datasets))
test.score <- dplyr::tibble(rmae=rmae(test.prediction$w, test.prediction$.pred)) %>%
knitr::kable()
print(test.score)
# test.residuals <- test.prediction %>%
#   dplyr::arrange(.pred) %>%
#   dplyr::mutate(residual_pct = (w - .pred) / .pred) %>%
#   dplyr::select(.pred, residual_pct)
# p <- ggplot2::ggplot(test.residuals, ggplot2::aes(x = .pred, y = residual_pct)) +
#   ggplot2::geom_point(size=0.5)+
#   ggplot2::xlab("Predicted w")+
#   ggplot2::ylab("Residual (%)")+
#   ggplot2::geom_smooth()+
#   ggplot2::theme_classic()
#
# png("%s/%s/Regression/%s/residuals_test_%s.png" %>% sprintf(inst$plot, inst$folder, subfolder, filename), width = 6, height = 6, res = 200, units = "in")
# print(p)
# dev.off()
}
}
main(path.list)
main(path.list)
make.datasets <- function(model, datasets, inst, subfolder="", filename="", on=T){
if (on){
# Check in train ----
source("functions/rmae.R")
preprocessing.recipe <- recipes::recipe(w ~ ., rsample::training(datasets)) %>% recipes::prep()
train.processed <- recipes::bake(preprocessing.recipe,  new_data = rsample::training(datasets))
train.prediction <- model %>%
# fit the model on all the training data
parsnip::fit(
formula = w ~ .,
data    = train.processed
)  %>%
predict(new_data = train.processed) %>%
dplyr::bind_cols(rsample::training(datasets))
train.score <- dplyr::tibble(rmae=rmae(train.prediction$w, train.prediction$.pred)) %>%
knitr::kable()
print(train.score)
# Check in test ----
test.processed <- recipes::bake(preprocessing.recipe,  new_data = rsample::testing(datasets))
test.prediction <- model %>%
parsnip::fit(
formula = w ~ .,
data    = test.processed
)
# Explainer ----
explainer <- DALEX::explain(
model=test.prediction,
data=rsample::testing(datasets),
y= rsample::testing(datasets)$w,
label="XGboost"
)
modelStudio::modelStudio(explainer, viewer="browser")
# test.prediction <- test.prediction %>%
#   predict(new_data = test.processed) %>%
#   dplyr::bind_cols(rsample::testing(datasets))
#
# test.score <- dplyr::tibble(rmae=rmae(test.prediction$w, test.prediction$.pred)) %>%
#   knitr::kable()
# print(test.score)
# test.residuals <- test.prediction %>%
#   dplyr::arrange(.pred) %>%
#   dplyr::mutate(residual_pct = (w - .pred) / .pred) %>%
#   dplyr::select(.pred, residual_pct)
# p <- ggplot2::ggplot(test.residuals, ggplot2::aes(x = .pred, y = residual_pct)) +
#   ggplot2::geom_point(size=0.5)+
#   ggplot2::xlab("Predicted w")+
#   ggplot2::ylab("Residual (%)")+
#   ggplot2::geom_smooth()+
#   ggplot2::theme_classic()
#
# png("%s/%s/Regression/%s/residuals_test_%s.png" %>% sprintf(inst$plot, inst$folder, subfolder, filename), width = 6, height = 6, res = 200, units = "in")
# print(p)
# dev.off()
}
}
main(path.list)
